{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0753b9f6",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'null' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-b39a0971bf27>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     18\u001b[0m   {\n\u001b[1;32m     19\u001b[0m    \u001b[0;34m\"cell_type\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m\"code\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m    \u001b[0;34m\"execution_count\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mnull\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m    \u001b[0;34m\"metadata\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m    \u001b[0;34m\"outputs\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'null' is not defined"
     ]
    }
   ],
   "source": [
    "{\n",
    " \"cells\": [\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"# 🧠 Function Approximation and Time Series Modeling\\n\",\n",
    "    \"\\n\",\n",
    "    \"**Author:** Your Name  \\n\",\n",
    "    \"**Date:** 2025-08-07\\n\",\n",
    "    \"\\n\",\n",
    "    \"This notebook demonstrates:\\n\",\n",
    "    \"- 1D function approximation using synthetic data\\n\",\n",
    "    \"- Time series modeling of a biological dynamic system (Lotka–Volterra equations)\\n\",\n",
    "    \"- Neural network regression using `scikit-learn`\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# 📦 Imports\\n\",\n",
    "    \"import numpy as np\\n\",\n",
    "    \"import matplotlib.pyplot as plt\\n\",\n",
    "    \"from scipy.integrate import solve_ivp\\n\",\n",
    "    \"from sklearn.neural_network import MLPRegressor\\n\",\n",
    "    \"from sklearn.preprocessing import StandardScaler\\n\",\n",
    "    \"from sklearn.metrics import mean_squared_error\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## 🔹 1D Synthetic Data\\n\",\n",
    "    \"\\n\",\n",
    "    \"We’ll create a 1D training dataset to use for function approximation.\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"x1_data = [-12, -10, -5, -2.5, 2, 4, 6, 7.5]\\n\",\n",
    "    \"Xtrain_1D = np.array(x1_data).reshape(-1, 1)\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## 🎯 Target Functions\\n\",\n",
    "    \"\\n\",\n",
    "    \"We define two functions:\\n\",\n",
    "    \"- A sinusoidal + quadratic function\\n\",\n",
    "    \"- A sum of three Gaussians\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Sinusoidal + Quadratic function\\n\",\n",
    "    \"def Sin_Square_1D(X, noise=False):\\n\",\n",
    "    \"    y = np.sin(X) + (X/5)**2\\n\",\n",
    "    \"    if noise:\\n\",\n",
    "    \"        n = np.random.normal(0, 0.03, X.shape[0])\\n\",\n",
    "    \"        return (y[:, 0] * (1 + n))\\n\",\n",
    "    \"    return y[:, 0]\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Sum of 3 Gaussians\\n\",\n",
    "    \"def gaus3_func(X, noise=False):\\n\",\n",
    "    \"    gaus_params = [[1.0, 2.0, -8.0], [1.5, 1.5, 0.0], [1.4, 1.0, 5.0]]\\n\",\n",
    "    \"    result = np.zeros(X.shape[0])\\n\",\n",
    "    \"    for a, std, mean in gaus_params:\\n\",\n",
    "    \"        result += a / (std * 2.5) * np.exp(-0.5 * ((X[:, 0] - mean)/std)**2)\\n\",\n",
    "    \"    if noise:\\n\",\n",
    "    \"        result += np.random.normal(0, 0.01, X.shape[0])\\n\",\n",
    "    \"    return -result\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## 📊 Visualize the Functions\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"Ytrain_SS1D = Sin_Square_1D(Xtrain_1D)\\n\",\n",
    "    \"Ytrain_3G = gaus3_func(Xtrain_1D)\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Plot\\n\",\n",
    "    \"plt.figure(figsize=(10, 4))\\n\",\n",
    "    \"plt.subplot(1, 2, 1)\\n\",\n",
    "    \"plt.title(\\\"Sin + Square Function\\\")\\n\",\n",
    "    \"plt.plot(Xtrain_1D, Ytrain_SS1D, 'bo-')\\n\",\n",
    "    \"plt.grid(True)\\n\",\n",
    "    \"\\n\",\n",
    "    \"plt.subplot(1, 2, 2)\\n\",\n",
    "    \"plt.title(\\\"Sum of 3 Gaussians\\\")\\n\",\n",
    "    \"plt.plot(Xtrain_1D, Ytrain_3G, 'ro-')\\n\",\n",
    "    \"plt.grid(True)\\n\",\n",
    "    \"plt.tight_layout()\\n\",\n",
    "    \"plt.show()\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## 🤖 MLPRegressor: Function Approximation\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Scale inputs\\n\",\n",
    "    \"scaler = StandardScaler()\\n\",\n",
    "    \"X_scaled = scaler.fit_transform(Xtrain_1D)\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Train MLP on Sin_Square_1D\\n\",\n",
    "    \"mlp = MLPRegressor(hidden_layer_sizes=(20, 20), max_iter=1000, random_state=1)\\n\",\n",
    "    \"mlp.fit(X_scaled, Ytrain_SS1D)\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Predict on a dense grid\\n\",\n",
    "    \"X_dense = np.linspace(-15, 10, 200).reshape(-1, 1)\\n\",\n",
    "    \"X_dense_scaled = scaler.transform(X_dense)\\n\",\n",
    "    \"Y_pred = mlp.predict(X_dense_scaled)\\n\",\n",
    "    \"Y_true = Sin_Square_1D(X_dense)\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Plot\\n\",\n",
    "    \"plt.figure(figsize=(8, 5))\\n\",\n",
    "    \"plt.plot(X_dense, Y_true, label=\\\"True Function\\\", color='black')\\n\",\n",
    "    \"plt.plot(X_dense, Y_pred, label=\\\"MLP Prediction\\\", linestyle='--')\\n\",\n",
    "    \"plt.scatter(Xtrain_1D, Ytrain_SS1D, color='red', label=\\\"Training Points\\\")\\n\",\n",
    "    \"plt.title(\\\"MLP Approximation of Sin + Square\\\")\\n\",\n",
    "    \"plt.xlabel(\\\"x\\\")\\n\",\n",
    "    \"plt.ylabel(\\\"y\\\")\\n\",\n",
    "    \"plt.grid(True)\\n\",\n",
    "    \"plt.legend()\\n\",\n",
    "    \"plt.show()\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Evaluate\\n\",\n",
    "    \"print(\\\"MSE:\\\", mean_squared_error(Y_true, Y_pred))\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## 🔄 Lotka–Volterra Predator-Prey Model\\n\",\n",
    "    \"This models the population dynamics of a prey and predator species over time.\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Define the equations\\n\",\n",
    "    \"def lotka_volterra(t, z, alpha=1.5, beta=1.0, delta=0.75, gamma=1.0):\\n\",\n",
    "    \"    x, y = z\\n\",\n",
    "    \"    dxdt = alpha * x - beta * x * y\\n\",\n",
    "    \"    dydt = delta * x * y - gamma * y\\n\",\n",
    "    \"    return [dxdt, dydt]\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Initial conditions and time span\\n\",\n",
    "    \"z0 = [10, 5]  # initial prey and predator\\n\",\n",
    "    \"t_span = (0, 15)\\n\",\n",
    "    \"t_eval = np.linspace(*t_span, 300)\\n\",\n",
    "    \"sol = solve_ivp(lotka_volterra, t_span, z0, t_eval=t_eval)\\n\",\n",
    "    \"t = sol.t\\n\",\n",
    "    \"x, y = sol.y\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Plot the time series\\n\",\n",
    "    \"plt.figure(figsize=(8, 5))\\n\",\n",
    "    \"plt.plot(t, x, label='Prey')\\n\",\n",
    "    \"plt.plot(t, y, label='Predator')\\n\",\n",
    "    \"plt.title(\\\"Predator-Prey Dynamics\\\")\\n\",\n",
    "    \"plt.xlabel(\\\"Time\\\")\\n\",\n",
    "    \"plt.ylabel(\\\"Population\\\")\\n\",\n",
    "    \"plt.legend()\\n\",\n",
    "    \"plt.grid(True)\\n\",\n",
    "    \"plt.show()\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## 🧩 Extensions and Ideas\\n\",\n",
    "    \"\\n\",\n",
    "    \"- Train a neural network to predict future population given history\\n\",\n",
    "    \"- Add noise to the data and test robustness\\n\",\n",
    "    \"- Try Gaussian Process Regression for function learning\\n\",\n",
    "    \"- Use real ecological data for comparison\"\n",
    "   ]\n",
    "  }\n",
    " ],\n",
    " \"metadata\": {\n",
    "  \"kernelspec\": {\n",
    "   \"display_name\": \"Python 3\",\n",
    "   \"language\": \"python\",\n",
    "   \"name\": \"python3\"\n",
    "  },\n",
    "  \"language_info\": {\n",
    "   \"name\": \"python\",\n",
    "   \"version\": \"\"\n",
    "  }\n",
    " },\n",
    " \"nbformat\": 4,\n",
    " \"nbformat_minor\": 5\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5053d79e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 📦 Imports\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.integrate import solve_ivp\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84dba6ad",
   "metadata": {},
   "source": [
    "## 🔹 1D Synthetic Data\n",
    "\n",
    "We'll create a 1D training dataset to use for function approximation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1e836ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "x1_data = [-12, -10, -5, -2.5, 2, 4, 6, 7.5]\n",
    "Xtrain_1D = np.array(x1_data).reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35dd9ea6",
   "metadata": {},
   "source": [
    "## 🎯 Target Functions\n",
    "\n",
    "We define two functions:\n",
    "- A sinusoidal + quadratic function\n",
    "- A sum of three Gaussians"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60071101",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sinusoidal + Quadratic function\n",
    "def Sin_Square_1D(X, noise=False):\n",
    "    y = np.sin(X) + (X/5)**2\n",
    "    if noise:\n",
    "        n = np.random.normal(0, 0.03, X.shape[0])\n",
    "        return (y[:, 0] * (1 + n))\n",
    "    return y[:, 0]\n",
    "\n",
    "# Sum of 3 Gaussians\n",
    "def gaus3_func(X, noise=False):\n",
    "    gaus_params = [[1.0, 2.0, -8.0], [1.5, 1.5, 0.0], [1.4, 1.0, 5.0]]\n",
    "    result = np.zeros(X.shape[0])\n",
    "    for a, std, mean in gaus_params:\n",
    "        result += a / (std * 2.5) * np.exp(-0.5 * ((X[:, 0] - mean)/std)**2)\n",
    "    if noise:\n",
    "        result += np.random.normal(0, 0.01, X.shape[0])\n",
    "    return -result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f08504e",
   "metadata": {},
   "source": [
    "## 📊 Visualize the Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c75dafb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "Ytrain_SS1D = Sin_Square_1D(Xtrain_1D)\n",
    "Ytrain_3G = gaus3_func(Xtrain_1D)\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(10, 4))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.title(\"Sin + Square Function\")\n",
    "plt.plot(Xtrain_1D, Ytrain_SS1D, 'bo-')\n",
    "plt.grid(True)\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.title(\"Sum of 3 Gaussians\")\n",
    "plt.plot(Xtrain_1D, Ytrain_3G, 'ro-')\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c7a5050",
   "metadata": {},
   "source": [
    "## 🤖 MLPRegressor: Function Approximation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91c7445b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale inputs\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(Xtrain_1D)\n",
    "\n",
    "# Train MLP on Sin_Square_1D\n",
    "mlp = MLPRegressor(hidden_layer_sizes=(20, 20), max_iter=1000, random_state=1)\n",
    "mlp.fit(X_scaled, Ytrain_SS1D)\n",
    "\n",
    "# Predict on a dense grid\n",
    "X_dense = np.linspace(-15, 10, 200).reshape(-1, 1)\n",
    "X_dense_scaled = scaler.transform(X_dense)\n",
    "Y_pred = mlp.predict(X_dense_scaled)\n",
    "Y_true = Sin_Square_1D(X_dense)\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.plot(X_dense, Y_true, label=\"True Function\", color='black')\n",
    "plt.plot(X_dense, Y_pred, label=\"MLP Prediction\", linestyle='--')\n",
    "plt.scatter(Xtrain_1D, Ytrain_SS1D, color='red', label=\"Training Points\")\n",
    "plt.title(\"MLP Approximation of Sin + Square\")\n",
    "plt.xlabel(\"x\")\n",
    "plt.ylabel(\"y\")\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Evaluate\n",
    "print(\"MSE:\", mean_squared_error(Y_true, Y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cd52e3e",
   "metadata": {},
   "source": [
    "## 🔄 Lotka–Volterra Predator-Prey Model\n",
    "This models the population dynamics of a prey and predator species over time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf7c055f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the equations\n",
    "def lotka_volterra(t, z, alpha=1.5, beta=1.0, delta=0.75, gamma=1.0):\n",
    "    x, y = z\n",
    "    dxdt = alpha * x - beta * x * y\n",
    "    dydt = delta * x * y - gamma * y\n",
    "    return [dxdt, dydt]\n",
    "\n",
    "# Initial conditions and time span\n",
    "z0 = [10, 5]  # initial prey and predator\n",
    "t_span = (0, 15)\n",
    "t_eval = np.linspace(*t_span, 300)\n",
    "sol = solve_ivp(lotka_volterra, t_span, z0, t_eval=t_eval)\n",
    "t = sol.t\n",
    "x, y = sol.y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad1cb0b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the time series\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.plot(t, x, label='Prey')\n",
    "plt.plot(t, y, label='Predator')\n",
    "plt.title(\"Predator-Prey Dynamics\")\n",
    "plt.xlabel(\"Time\")\n",
    "plt.ylabel(\"Population\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8eec494a",
   "metadata": {},
   "source": [
    "## 🧩 Extensions and Ideas\n",
    "\n",
    "- Train a neural network to predict future population given history\n",
    "- Add noise to the data and test robustness\n",
    "- Try Gaussian Process Regression for function learning\n",
    "- Use real ecological data for comparison"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cd4321c",
   "metadata": {},
   "source": [
    "## 🔮 Time Series Prediction with Neural Networks\n",
    "\n",
    "Let's implement a neural network to predict future population dynamics based on historical data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d373c914",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_sequences(data, seq_length):\n",
    "    \"\"\"Create sliding window sequences for time series prediction\"\"\"\n",
    "    X, y = [], []\n",
    "    for i in range(len(data) - seq_length):\n",
    "        X.append(data[i:(i + seq_length)])\n",
    "        y.append(data[i + seq_length])\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "# Prepare time series data for neural network prediction\n",
    "seq_length = 20  # Use 20 time steps to predict the next step\n",
    "\n",
    "# Create sequences for both prey and predator populations\n",
    "X_prey, y_prey = create_sequences(x, seq_length)\n",
    "X_pred, y_pred = create_sequences(y, seq_length)\n",
    "\n",
    "print(f\"Prey sequences shape: {X_prey.shape}, targets shape: {y_prey.shape}\")\n",
    "print(f\"Predator sequences shape: {X_pred.shape}, targets shape: {y_pred.shape}\")\n",
    "\n",
    "# Split data for training and testing\n",
    "split_idx = int(0.8 * len(X_prey))\n",
    "X_prey_train, X_prey_test = X_prey[:split_idx], X_prey[split_idx:]\n",
    "y_prey_train, y_prey_test = y_prey[:split_idx], y_prey[split_idx:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f570788",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train MLPRegressor for time series prediction\n",
    "scaler_ts = StandardScaler()\n",
    "X_prey_train_scaled = scaler_ts.fit_transform(X_prey_train)\n",
    "X_prey_test_scaled = scaler_ts.transform(X_prey_test)\n",
    "\n",
    "# Create and train the neural network\n",
    "mlp_ts = MLPRegressor(\n",
    "    hidden_layer_sizes=(50, 30, 10),\n",
    "    max_iter=2000,\n",
    "    random_state=42,\n",
    "    learning_rate_init=0.001,\n",
    "    early_stopping=True,\n",
    "    validation_fraction=0.1\n",
    ")\n",
    "\n",
    "mlp_ts.fit(X_prey_train_scaled, y_prey_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred_train = mlp_ts.predict(X_prey_train_scaled)\n",
    "y_pred_test = mlp_ts.predict(X_prey_test_scaled)\n",
    "\n",
    "# Calculate metrics\n",
    "train_mse = mean_squared_error(y_prey_train, y_pred_train)\n",
    "test_mse = mean_squared_error(y_prey_test, y_pred_test)\n",
    "\n",
    "print(f\"Training MSE: {train_mse:.4f}\")\n",
    "print(f\"Testing MSE: {test_mse:.4f}\")\n",
    "print(f\"Model R² Score: {mlp_ts.score(X_prey_test_scaled, y_prey_test):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa4395af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the predictions\n",
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "# Plot 1: Training predictions\n",
    "plt.subplot(2, 2, 1)\n",
    "plt.plot(y_prey_train[:50], label='True Values', alpha=0.7)\n",
    "plt.plot(y_pred_train[:50], label='Predictions', alpha=0.7)\n",
    "plt.title('Training Predictions (First 50 points)')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "# Plot 2: Test predictions\n",
    "plt.subplot(2, 2, 2)\n",
    "plt.plot(y_prey_test, label='True Values', alpha=0.7)\n",
    "plt.plot(y_pred_test, label='Predictions', alpha=0.7)\n",
    "plt.title('Test Predictions')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "# Plot 3: Prediction vs True scatter plot\n",
    "plt.subplot(2, 2, 3)\n",
    "plt.scatter(y_prey_test, y_pred_test, alpha=0.6)\n",
    "plt.plot([y_prey_test.min(), y_prey_test.max()], \n",
    "         [y_prey_test.min(), y_prey_test.max()], 'r--', lw=2)\n",
    "plt.xlabel('True Values')\n",
    "plt.ylabel('Predictions')\n",
    "plt.title('Prediction vs True Values')\n",
    "plt.grid(True)\n",
    "\n",
    "# Plot 4: Residuals\n",
    "plt.subplot(2, 2, 4)\n",
    "residuals = y_prey_test - y_pred_test\n",
    "plt.scatter(y_pred_test, residuals, alpha=0.6)\n",
    "plt.axhline(y=0, color='r', linestyle='--')\n",
    "plt.xlabel('Predictions')\n",
    "plt.ylabel('Residuals')\n",
    "plt.title('Residual Plot')\n",
    "plt.grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22b44ad1",
   "metadata": {},
   "source": [
    "## 🔊 Noise Robustness Testing\n",
    "\n",
    "Let's test how robust our models are to different levels of noise in the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41724a7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test robustness with different noise levels\n",
    "noise_levels = [0.0, 0.05, 0.1, 0.15, 0.2]\n",
    "mse_scores = []\n",
    "\n",
    "plt.figure(figsize=(15, 10))\n",
    "\n",
    "for i, noise_level in enumerate(noise_levels):\n",
    "    # Add noise to the original functions\n",
    "    Ytrain_SS1D_noisy = Sin_Square_1D(Xtrain_1D, noise=False)\n",
    "    if noise_level > 0:\n",
    "        noise = np.random.normal(0, noise_level, Ytrain_SS1D_noisy.shape)\n",
    "        Ytrain_SS1D_noisy += noise\n",
    "    \n",
    "    # Train model with noisy data\n",
    "    scaler_noise = StandardScaler()\n",
    "    X_scaled_noise = scaler_noise.fit_transform(Xtrain_1D)\n",
    "    \n",
    "    mlp_noise = MLPRegressor(hidden_layer_sizes=(20, 20), max_iter=1000, random_state=1)\n",
    "    mlp_noise.fit(X_scaled_noise, Ytrain_SS1D_noisy)\n",
    "    \n",
    "    # Test on clean data\n",
    "    X_dense_scaled_noise = scaler_noise.transform(X_dense)\n",
    "    Y_pred_noise = mlp_noise.predict(X_dense_scaled_noise)\n",
    "    Y_true_clean = Sin_Square_1D(X_dense)\n",
    "    \n",
    "    mse = mean_squared_error(Y_true_clean, Y_pred_noise)\n",
    "    mse_scores.append(mse)\n",
    "    \n",
    "    # Plot results\n",
    "    plt.subplot(2, 3, i+1)\n",
    "    plt.plot(X_dense, Y_true_clean, label=\"True Function\", color='black', linewidth=2)\n",
    "    plt.plot(X_dense, Y_pred_noise, label=\"MLP Prediction\", linestyle='--', alpha=0.8)\n",
    "    plt.scatter(Xtrain_1D, Ytrain_SS1D_noisy, color='red', alpha=0.6, label=\"Noisy Training\")\n",
    "    plt.title(f'Noise Level: {noise_level:.2f}\\nMSE: {mse:.4f}')\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    if i == 0:\n",
    "        plt.legend()\n",
    "\n",
    "# Plot MSE vs Noise Level\n",
    "plt.subplot(2, 3, 6)\n",
    "plt.plot(noise_levels, mse_scores, 'bo-', linewidth=2, markersize=8)\n",
    "plt.xlabel('Noise Level')\n",
    "plt.ylabel('MSE on Clean Data')\n",
    "plt.title('Model Robustness to Training Noise')\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"Noise Robustness Results:\")\n",
    "for noise, mse in zip(noise_levels, mse_scores):\n",
    "    print(f\"Noise Level {noise:.2f}: MSE = {mse:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e847f4c3",
   "metadata": {},
   "source": [
    "## 🎯 Gaussian Process Regression\n",
    "\n",
    "Let's implement Gaussian Process Regression for function learning and compare it with our neural network approach."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbb3afe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.gaussian_process.kernels import RBF, ConstantKernel as C, WhiteKernel\n",
    "\n",
    "# Define different kernels to test\n",
    "kernels = {\n",
    "    'RBF': C(1.0) * RBF(1.0),\n",
    "    'RBF + Noise': C(1.0) * RBF(1.0) + WhiteKernel(1e-2),\n",
    "    'RBF (optimized)': C(1.0, (1e-3, 1e3)) * RBF(1.0, (1e-2, 1e2))\n",
    "}\n",
    "\n",
    "plt.figure(figsize=(15, 5))\n",
    "\n",
    "for i, (kernel_name, kernel) in enumerate(kernels.items()):\n",
    "    # Create and fit Gaussian Process\n",
    "    gp = GaussianProcessRegressor(\n",
    "        kernel=kernel,\n",
    "        n_restarts_optimizer=10,\n",
    "        random_state=42\n",
    "    )\n",
    "    \n",
    "    gp.fit(Xtrain_1D, Ytrain_SS1D)\n",
    "    \n",
    "    # Make predictions with uncertainty\n",
    "    Y_pred_gp, Y_std_gp = gp.predict(X_dense, return_std=True)\n",
    "    \n",
    "    # Calculate metrics\n",
    "    Y_true_dense = Sin_Square_1D(X_dense)\n",
    "    mse_gp = mean_squared_error(Y_true_dense, Y_pred_gp)\n",
    "    \n",
    "    # Plot results\n",
    "    plt.subplot(1, 3, i+1)\n",
    "    plt.plot(X_dense, Y_true_dense, 'k-', label='True Function', linewidth=2)\n",
    "    plt.plot(X_dense, Y_pred_gp, 'b-', label='GP Prediction', alpha=0.8)\n",
    "    plt.fill_between(X_dense.ravel(), \n",
    "                     Y_pred_gp - 1.96 * Y_std_gp,\n",
    "                     Y_pred_gp + 1.96 * Y_std_gp,\n",
    "                     alpha=0.3, color='blue', label='95% Confidence')\n",
    "    plt.scatter(Xtrain_1D, Ytrain_SS1D, c='red', s=50, alpha=0.8, label='Training Data')\n",
    "    plt.title(f'{kernel_name}\\nMSE: {mse_gp:.4f}')\n",
    "    plt.xlabel('x')\n",
    "    plt.ylabel('y')\n",
    "    plt.legend()\n",
    "    plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Compare GP with MLP\n",
    "print(\"\\\\nModel Comparison:\")\n",
    "print(f\"MLP MSE: {mean_squared_error(Y_true, Y_pred):.4f}\")\n",
    "print(f\"GP (RBF + Noise) MSE: {mse_gp:.4f}\")\n",
    "print(f\"GP provides uncertainty estimates: ±{Y_std_gp.mean():.3f} (average std)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56e201a5",
   "metadata": {},
   "source": [
    "## 📊 Model Performance Summary\n",
    "\n",
    "Let's create a comprehensive comparison of all models and their performance metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd92fab8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import r2_score, mean_absolute_error\n",
    "\n",
    "# Create performance comparison\n",
    "models_performance = []\n",
    "\n",
    "# Re-calculate metrics for fair comparison\n",
    "Y_true_comparison = Sin_Square_1D(X_dense)\n",
    "\n",
    "# MLP Performance\n",
    "mlp_pred = mlp.predict(scaler.transform(X_dense))\n",
    "models_performance.append({\n",
    "    'Model': 'MLP Regressor',\n",
    "    'MSE': mean_squared_error(Y_true_comparison, mlp_pred),\n",
    "    'MAE': mean_absolute_error(Y_true_comparison, mlp_pred),\n",
    "    'R²': r2_score(Y_true_comparison, mlp_pred),\n",
    "    'Provides Uncertainty': 'No',\n",
    "    'Training Time': 'Fast'\n",
    "})\n",
    "\n",
    "# GP Performance (using last GP model)\n",
    "gp_pred, gp_std = gp.predict(X_dense, return_std=True)\n",
    "models_performance.append({\n",
    "    'Model': 'Gaussian Process',\n",
    "    'MSE': mean_squared_error(Y_true_comparison, gp_pred),\n",
    "    'MAE': mean_absolute_error(Y_true_comparison, gp_pred),\n",
    "    'R²': r2_score(Y_true_comparison, gp_pred),\n",
    "    'Provides Uncertainty': 'Yes',\n",
    "    'Training Time': 'Moderate'\n",
    "})\n",
    "\n",
    "# Time Series MLP Performance\n",
    "if 'mlp_ts' in globals():\n",
    "    models_performance.append({\n",
    "        'Model': 'Time Series MLP',\n",
    "        'MSE': test_mse,\n",
    "        'MAE': mean_absolute_error(y_prey_test, y_pred_test),\n",
    "        'R²': mlp_ts.score(X_prey_test_scaled, y_prey_test),\n",
    "        'Provides Uncertainty': 'No',\n",
    "        'Training Time': 'Fast'\n",
    "    })\n",
    "\n",
    "# Create performance DataFrame\n",
    "df_performance = pd.DataFrame(models_performance)\n",
    "print(\"🏆 Model Performance Comparison\")\n",
    "print(\"=\" * 60)\n",
    "print(df_performance.round(4).to_string(index=False))\n",
    "\n",
    "# Visualization of model comparison\n",
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "# Plot 1: MSE Comparison\n",
    "plt.subplot(2, 2, 1)\n",
    "models = df_performance['Model']\n",
    "mse_values = df_performance['MSE']\n",
    "bars = plt.bar(models, mse_values, color=['skyblue', 'lightcoral', 'lightgreen'][:len(models)])\n",
    "plt.title('Mean Squared Error Comparison')\n",
    "plt.ylabel('MSE')\n",
    "plt.xticks(rotation=45)\n",
    "for bar, value in zip(bars, mse_values):\n",
    "    plt.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.001,\n",
    "             f'{value:.4f}', ha='center', va='bottom')\n",
    "\n",
    "# Plot 2: R² Comparison\n",
    "plt.subplot(2, 2, 2)\n",
    "r2_values = df_performance['R²']\n",
    "bars = plt.bar(models, r2_values, color=['skyblue', 'lightcoral', 'lightgreen'][:len(models)])\n",
    "plt.title('R² Score Comparison')\n",
    "plt.ylabel('R²')\n",
    "plt.xticks(rotation=45)\n",
    "for bar, value in zip(bars, r2_values):\n",
    "    plt.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.01,\n",
    "             f'{value:.4f}', ha='center', va='bottom')\n",
    "\n",
    "# Plot 3: Model Predictions Comparison\n",
    "plt.subplot(2, 1, 2)\n",
    "plt.plot(X_dense, Y_true_comparison, 'k-', label='True Function', linewidth=3)\n",
    "plt.plot(X_dense, mlp_pred, '--', label='MLP Prediction', alpha=0.8, linewidth=2)\n",
    "plt.plot(X_dense, gp_pred, ':', label='GP Prediction', alpha=0.8, linewidth=2)\n",
    "if len(gp_std) > 0:\n",
    "    plt.fill_between(X_dense.ravel(), \n",
    "                     gp_pred - 1.96 * gp_std,\n",
    "                     gp_pred + 1.96 * gp_std,\n",
    "                     alpha=0.2, color='red', label='GP 95% Confidence')\n",
    "plt.scatter(Xtrain_1D, Ytrain_SS1D, c='red', s=50, alpha=0.8, label='Training Data')\n",
    "plt.title('Model Predictions Comparison')\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('y')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
